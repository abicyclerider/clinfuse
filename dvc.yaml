vars:
- params.yaml

stages:
  generate:
    cmd: >-
      rm -rf synthea_runner/output/synthea_raw &&
      docker build -t synthea synthea_runner/synthea-docker/ &&
      docker run --rm
      -e JAVA_OPTS=-Xmx8g
      -v $(pwd)/synthea_runner/output/synthea_raw:/synthea/synthea/output
      synthea
      /bin/sh -c "./run_synthea -p ${generate.population} -s ${generate.seed}
      --exporter.baseDirectory=./output --exporter.csv.export=true
      --exporter.fhir.export=false Massachusetts"
    params:
    - generate.population
    - generate.seed
    deps:
    - synthea_runner/synthea-docker/Dockerfile
    outs:
    - synthea_runner/output/synthea_raw/csv:
        cache: false

  augment:
    cmd: >-
      rm -rf output/augmented &&
      docker build -t augmentation augmentation/ &&
      docker run --rm
      -v $(pwd)/synthea_runner/output/synthea_raw/csv:/data/input:ro
      -v $(pwd)/output/augmented:/data/output
      augmentation
      --input /data/input
      --output /data/output
      --random-seed ${augment.random_seed}
    params:
    - augment.random_seed
    deps:
    - synthea_runner/output/synthea_raw/csv
    - augmentation/Dockerfile
    - augmentation/requirements-runtime.txt
    - augmentation/cli/augment.py
    - augmentation/config/default_config.yaml
    outs:
    - output/augmented:
        cache: false

  resolve:
    cmd: >-
      rm -rf output/resolved &&
      docker build -f entity_resolution/Dockerfile -t entity_resolution . &&
      docker run --rm
      -v $(pwd)/output/augmented:/data/augmented:ro
      -v $(pwd)/output/resolved:/data/resolved
      entity_resolution
      python -m entity_resolution.resolve
      --augmented-dir /data/augmented
      --output-dir /data/resolved
      --config entity_resolution/config/matching_config.yaml
    params:
    - resolve.auto_match_probability
    - resolve.auto_reject_probability
    deps:
    - output/augmented
    - entity_resolution/Dockerfile
    - entity_resolution/resolve.py
    - entity_resolution/core/
    - entity_resolution/config/matching_config.yaml
    - entity_resolution/requirements-runtime.txt
    - shared/
    outs:
    - output/resolved:
        cache: false

  infer:
    cmd: >-
      rm -rf output/inferred &&
      mkdir -p output/inferred &&
      fine_tuning/infer_remote.sh
      output/resolved/gray_zone_pairs.parquet
      output/inferred/predictions.parquet
    deps:
    - fine_tuning/Dockerfile
    - fine_tuning/_remote_helpers.sh
    - fine_tuning/infer_remote.sh
    - fine_tuning/infer_classifier.py
    - fine_tuning/requirements.txt
    - fine_tuning/launch_pod.sh
    - output/resolved/gray_zone_pairs.parquet
    outs:
    - output/inferred/predictions.parquet:
        cache: false

  golden_records:
    cmd: >-
      rm -rf output/golden_records &&
      docker run --rm
      -v $(pwd)/output/augmented:/data/augmented:ro
      -v $(pwd)/output/resolved:/data/resolved:ro
      -v $(pwd)/output/inferred:/data/inferred:ro
      -v $(pwd)/output/golden_records:/data/golden_records
      entity_resolution
      python -m entity_resolution.build_golden_records
      --augmented-dir /data/augmented
      --auto-matches /data/resolved/auto_matches.parquet
      --predictions /data/inferred/predictions.parquet
      --features /data/resolved/features.parquet
      --output-dir /data/golden_records
      --config entity_resolution/config/matching_config.yaml
    deps:
    - output/resolved/auto_matches.parquet
    - output/resolved/features.parquet
    - output/inferred/predictions.parquet
    - output/augmented
    - entity_resolution/build_golden_records.py
    - entity_resolution/core/
    - shared/
    outs:
    - output/golden_records:
        cache: false

  generate_training:
    cmd: >-
      rm -rf output/training/synthea_raw &&
      docker build -t synthea synthea_runner/synthea-docker/ &&
      docker run --rm
      -e JAVA_OPTS=-Xmx8g
      -v $(pwd)/output/training/synthea_raw:/synthea/synthea/output
      synthea
      /bin/sh -c "./run_synthea -p ${generate_training.population} -s ${generate_training.seed}
      --exporter.baseDirectory=./output --exporter.csv.export=true
      --exporter.fhir.export=false Massachusetts"
    params:
    - generate_training.population
    - generate_training.seed
    deps:
    - synthea_runner/synthea-docker/Dockerfile
    outs:
    - output/training/synthea_raw/csv:
        cache: false

  augment_training:
    cmd: >-
      rm -rf output/training/augmented &&
      docker build -t augmentation augmentation/ &&
      docker run --rm
      -v $(pwd)/output/training/synthea_raw/csv:/data/input:ro
      -v $(pwd)/output/training/augmented:/data/output
      augmentation
      --input /data/input
      --output /data/output
      --random-seed ${augment_training.random_seed}
    params:
    - augment_training.random_seed
    deps:
    - output/training/synthea_raw/csv
    - augmentation/Dockerfile
    - augmentation/requirements-runtime.txt
    - augmentation/cli/augment.py
    - augmentation/config/default_config.yaml
    outs:
    - output/training/augmented:
        cache: false

  prepare_dataset:
    cmd: >-
      rm -rf output/training/dataset &&
      mkdir -p output/training/dataset &&
      python fine_tuning/prepare_dataset.py
      --augmented-dir output/training/augmented
      --output-dir output/training/dataset
      --seed ${prepare_dataset.seed}
    params:
    - prepare_dataset.seed
    deps:
    - output/training/augmented
    - fine_tuning/prepare_dataset.py
    - shared/summarize.py
    - shared/data_loader.py
    - shared/ground_truth.py
    - shared/medical_records.py
    outs:
    - output/training/dataset/dataset_info.json:
        cache: false

  train:
    cmd: >-
      rm -rf output/training/train &&
      mkdir -p output/training/train &&
      fine_tuning/train_remote.sh
      --gpu-type "NVIDIA H100 80GB HBM3"
      output/training/train
      --
      --epochs ${train.epochs}
      --batch-size ${train.batch_size}
      --lr ${train.lr}
      --max-length ${train.max_length}
      --lora-r ${train.lora_r}
    params:
    - train.epochs
    - train.batch_size
    - train.lr
    - train.max_length
    - train.lora_r
    deps:
    - output/training/dataset/dataset_info.json
    - fine_tuning/train_classifier.py
    - fine_tuning/train_remote.sh
    - fine_tuning/_remote_helpers.sh
    - fine_tuning/launch_pod.sh
    - fine_tuning/Dockerfile
    - fine_tuning/requirements.txt
    outs:
    - output/training/train/train_metrics.json:
        cache: false

  export:
    cmd: >-
      rm -rf output/training/export &&
      mkdir -p output/training/export &&
      fine_tuning/export_remote.sh
      --gpu-type "NVIDIA H100 80GB HBM3"
      output/training/export
    deps:
    - output/training/train/train_metrics.json
    - fine_tuning/export_model.py
    - fine_tuning/export_remote.sh
    - fine_tuning/_remote_helpers.sh
    - fine_tuning/launch_pod.sh
    - fine_tuning/Dockerfile
    - fine_tuning/requirements.txt
    outs:
    - output/training/export/export_info.json:
        cache: false
